{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hadoop query : hdfs + pig + hive\n",
    "\n",
    "#### author: lhphong@tma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.  Hadoop Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-c53cfdfb1a7b>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-c53cfdfb1a7b>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    hodoop fs -ls /\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Show databases\n",
    "hodoop fs -ls / \n",
    "\n",
    "# Create folder on HDFS\n",
    "hadoop fs -mkdir -p user/local/temp\n",
    "\n",
    "# Remove file or folder on HDFS\n",
    "hadoop fs -rm -R -skipTrash /name_file\n",
    "\n",
    "# \n",
    "hdfs dfs -chmod g+w /user/hive/warehouse\n",
    "hdfs dfs -chmod g+w /tmp\n",
    "\n",
    "# Put file data from local to HDFS\n",
    "hadoop fs -put 'home/lhphong/Desktop/MOCK_DATA.csv' 'user/local/temp/data-customer.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Pig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Local mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-d6bb9ef6f881>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-d6bb9ef6f881>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    pig -x local\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Load data from local\n",
    "pig -x local\n",
    "data = load '/home/lhphong/Desktop/MOCK_DATA.csv' using PigStorage(',') as (id,first_name,last_name,email,gender,age,address);\n",
    "\n",
    "# Show data\n",
    "dump data;\n",
    "\n",
    "# Show describe data\n",
    "describe data;\n",
    "\n",
    "# Quit\n",
    "quit;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MapReduce mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-b82f39318b09>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-b82f39318b09>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    pig -x mapreduce\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# load data map reduce - HDFS model\n",
    "pig -x mapreduce\n",
    "data = load '/tmp/data-customer.csv' using PigStorage(',') as (id:int,first_name:chararray,last_name:chararray,email:chararray);\n",
    "bag1 = load 'home/lhphong/Desktop/tuple.data' Using PigStorage(' ') \n",
    "    as (B1:Bag{t1:tuple(t1a:int, t1b:int, t1c: int}, B2:Bag{t2:tuple(t2a:int, t2b:int)});\n",
    "tuplebag = load 'home/lhphong/Desktop/tuple.data' Using PigStorage(' ') \n",
    "    as (t1:tuple(t1a:int, t1b:int, t1c: int), t2:tuple(t2a:int, t2b:int)), (B1:Bag{t1:tuple(t1a:int, t1b:int, t1c: int});\n",
    "\n",
    "# Show data\n",
    "dump data;\n",
    "\n",
    "# Show describe\n",
    "describe data;\n",
    "\n",
    "# Quit\n",
    "quit;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-59bd8a1150f2>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-59bd8a1150f2>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    store customers into '/tmp/output';\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Export query save on HDFS\n",
    "store customers into '/tmp/output';\n",
    "\n",
    "# LIMIT\n",
    "limit = LIMIT customers 50;\n",
    "\n",
    "# SPLIT keyword\n",
    "SPLIT customers into AGE19 if $5 == 19, AGE40 if $5 == 40;\n",
    "dump AGE19;\n",
    "dump AGE40;\n",
    "\n",
    "# Distinct keyword\n",
    "distinct2 = DISTINCT distinct1;\n",
    "dump distinct2;\n",
    "\n",
    "# SAMPLE keyword: select random data 10% data == 0.1\n",
    "sample1 = SAMPLE customers 0.1;\n",
    "dump sipble1;\n",
    "\n",
    "# FILTER data BY ...\n",
    "filter1 = FILTER customers BY age == 19; or filter1 = FILTER customers BY $5 eq 19; # age == $5\n",
    "filter2 = FILTER customers BY $5 > 40; or filter2 = FILTER customers BY $5 gt 40;\n",
    "filter3 = FILTER customers BY $5 < 40; or filter3 = FILTER customers BY $5 lt 40;\n",
    "filter4 = FILTER customers BY NOT age == 19; or filter4 = FILTER customers BY NOT $5 eq 19;\n",
    "filter5 = FILTER customers BY age in (19,40); or filter5 = FILTER customers BY $5 in (19,40);\n",
    "filter6 = FILTER customers BY address MATCHES 'C.*a'; \n",
    "filter6 = FILTER customers BY address MATCHES '.*(le|en).*';\n",
    "\n",
    "# ORDER\n",
    "order1 = ORDER customers BY age asc;\n",
    "order2 = ORDER customers BY age desc;\n",
    "dunmp order;\n",
    "\n",
    "# GROUP BY\n",
    "group1 = GROUP customers BY age;\n",
    "group1 = GROUP customers BY (address, age);\n",
    "dump group1;\n",
    "\n",
    "# COGROUP\n",
    "cogroup1 = COGROUP a by a1, b by b2\n",
    "cogroup1 = COGROUP a by a1 inner, b by b2\n",
    "cogroup1 = COGROUP a by a1, b by b2 inner\n",
    "dump cogroup;\n",
    "\n",
    "# FOREACH\n",
    "x = FOREACH A GENERATE *;\n",
    "x = FOREACH A GENERATE a1, a2;\n",
    "x = FOREACH C GENERATE group, B.b2;\n",
    "x = FOREACH C GENERATE group, A.(a1, a2);\n",
    "x = FOREACH A GENERATE a1+a2 AS f1:int;\n",
    "y = FILTER X BY f1 > 10;\n",
    "\n",
    "# JOIN (inner)\n",
    "alias = JOIN A BY a1, B BY b1;\n",
    "\n",
    "# JOIN (outer)\n",
    "C = JOIN A by $0 LEFT OUTER, B BY $0;        # Left outer join.\n",
    "C = JOIN A BY $0 FULL, B BY $0;           # Full outer join.\n",
    "C= JOIN A BY $0 LEFT, B BY $0 USING 'replicated';     # USING keyword \n",
    "C= JOIN A BY $0 RIGHT, B BY $0 USING 'bloom';         # Right outer join.\n",
    "C = JOIN A BY name FULL, B BY name USING 'skewed';      # Full outer join.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Hive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-a55c5814ac9a>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-a55c5814ac9a>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    CREATE SCHEMA IF NOT EXISTS `demo_hive`;\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Create database\n",
    "CREATE SCHEMA IF NOT EXISTS `demo_hive`;\n",
    "\n",
    "# Create table \"offers\" in database \"demo_hive\"\n",
    "USE demo_apache_hive;\n",
    "\n",
    "CREATE EXTERNAL TABLE offers (offerid BIGINT,category BIGINT,quantity INT,company BIGINT,offervalue DOUBLE,brand BIGINT)\n",
    "ROW FORMAT DELIMITED FIELDS TERMINATED BY ','\n",
    "STORED AS TEXTFILE\n",
    "tblproperties(\"skip.header.line.count\"=\"1\"); \n",
    "\n",
    "# Load data for table \"offers\"\n",
    "LOAD DATA local inpath \"/home/lhphong/Desktop/offers.csv\" INTO table offers;\n",
    "\n",
    "# Select query\n",
    "SELECT * from offers LIMIT 5;\n",
    "\n",
    "# Drop database\n",
    "DROP TABLE IF EXISTS offers;\n",
    "\n",
    "# Alter in table\n",
    "ALTER TABLE name RENAME TO new_name\n",
    "ALTER TABLE name ADD COLUMNS (col_spec[, col_spec ...])\n",
    "ALTER TABLE name DROP [COLUMN] column_name\n",
    "ALTER TABLE name CHANGE column_name new_name new_type\n",
    "ALTER TABLE name REPLACE COLUMNS (col_spec[, col_spec ...])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-8-ed0db3472bd1>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-ed0db3472bd1>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    SELECT [ALL | DISTINCT] select_expr, select_expr, ...\u001b[0m\n\u001b[0m                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Select ... Where\n",
    "SELECT [ALL | DISTINCT] select_expr, select_expr, ... \n",
    "FROM table_reference \n",
    "[WHERE where_condition] \n",
    "[GROUP BY col_list] \n",
    "[HAVING having_condition] \n",
    "[CLUSTER BY col_list | [DISTRIBUTE BY col_list] [SORT BY col_list]] \n",
    "[LIMIT number];\n",
    "\n",
    "# Select ... Order\n",
    "SELECT [ALL | DISTINCT] select_expr, select_expr, ... \n",
    "FROM table_reference \n",
    "[WHERE where_condition] \n",
    "[GROUP BY col_list] \n",
    "[HAVING having_condition] \n",
    "[ORDER BY col_list]] \n",
    "[LIMIT number];\n",
    "\n",
    "# Select ... Group by\n",
    "SELECT [ALL | DISTINCT] select_expr, select_expr, ... \n",
    "FROM table_reference \n",
    "[WHERE where_condition] \n",
    "[GROUP BY col_list] \n",
    "[HAVING having_condition] \n",
    "[ORDER BY col_list]] \n",
    "[LIMIT number];\n",
    "\n",
    "# Select Joins\n",
    "hive> SELECT c.ID, c.NAME, c.AGE, o.AMOUNT \n",
    "FROM CUSTOMERS c JOIN ORDERS o \n",
    "ON (c.ID = o.CUSTOMER_ID);\n",
    "\n",
    "hive> SELECT c.ID, c.NAME, o.AMOUNT, o.DATE    # Joins Left\n",
    "FROM CUSTOMERS c \n",
    "LEFT OUTER JOIN ORDERS o \n",
    "ON (c.ID = o.CUSTOMER_ID);\n",
    "\n",
    "hive> SELECT c.ID, c.NAME, o.AMOUNT, o.DATE # FULL OUTER JOIN\n",
    "FROM CUSTOMERS c \n",
    "FULL OUTER JOIN ORDERS o \n",
    "ON (c.ID = o.CUSTOMER_ID);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
